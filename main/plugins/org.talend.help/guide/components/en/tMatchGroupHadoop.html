<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>tMatchGroupHadoop</title><meta name="generator" content="DocBook XSL-NS Stylesheets V1.75.2"><link rel="home" href="bk-tdi-components-rg-en..html" title="Talend Components"><link rel="up" href="ch-dataquality.html" title="Chapter&nbsp;6.&nbsp;Data Quality components"><link rel="prev" href="tMatchGroup.html" title="tMatchGroup"><link rel="next" href="tMelissaDataAddress.html" title="tMelissaDataAddress"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">tMatchGroupHadoop</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="tMatchGroup.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;6.&nbsp;Data Quality components</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="tMelissaDataAddress.html">Next</a></td></tr></table><hr></div><div lang="EN" class="section" title="tMatchGroupHadoop"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="tMatchGroupHadoop"></a>tMatchGroupHadoop</h2></div></div></div><div class="mediaobject"><img src="../images/tMatchGroupHadoop_icon32_white.png"></div><div class="warning" title="Warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>This component will be available in the <span class="emphasis"><strong>Palette</strong></span> of
			the studio on the condition that you have subscribed to any <span class="emphasis"><em>Talend Platform</em></span> product.</p></div><div class="section" title="tMatchGroupHadoop properties"><div class="titlepage"><div><div><h3 class="title"><a name="ychen-20111020-data_quality-properties"></a>tMatchGroupHadoop properties</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Component family</strong></span>
							</p>
						</td><td valign="top">
							<p>Data Quality</p>
						</td><td valign="top">&nbsp;</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Function</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p><span class="emphasis"><strong>tMatchGroupHadoop</strong></span> uses given
								matching rule(s) to compare columns of the data in HDFS and groups
								accordingly encountered duplicates in the output flow.</p>
							<p>When several <span class="emphasis"><strong>tMatchGroupHadoop</strong></span>
								components are used sequentially, the first one creates the groups
								of similar records and the others coming after refine the groups
								they receive from their preceding ones, one after the other. </p>
							<p>In defining a group, the first record processed of each group is
								the master record of the group; the other records are computed as to
								their distances from the master records and then are distributed to
								the due master record accordingly. In refining the given groups, a
								group with one single record (the group size is one) is compared
								with the other master records and is merged into one of the other
								groups as determined by the distances recomputed in between.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Purpose</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>This component helps ensure the quality of any source data of
								large volume.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Basic settings</strong></span>
							</p>
						</td><td valign="top">
							<p><span class="emphasis"><em>Schema</em></span> and <span class="emphasis"><em>Edit
								schema</em></span></p>
						</td><td valign="top">
							<p>A schema is a row description, i.e., it defines the number of
								fields that will be processed and passed on to the next component.
								The schema is either built-in or remote in the Repository.</p>
							<p>Click <span class="emphasis"><strong>Sync columns</strong></span> to retrieve
								the schema from the previous component in the Job.</p>
							<p>The output schema of this component contains the following
								fields:</p>
							<p><span class="emphasis"><em>GID</em></span>: represents the group identifier.</p>
							<p><span class="emphasis"><em>GRP_SIZE</em></span>: counts the number of records in the
								group, computed only on the master record.</p>
							<p><span class="emphasis"><em>MASTER</em></span>: identifies the record used in the
								matching comparisons. There is only one master record per group.
								Each input record will be compared to a master record, if they
								match, it will be placed into the group.</p>
							<p><span class="emphasis"><em>SCORE</em></span>: measures the distance between the
								input record and the master record according to the matching
								algorithm used.</p>
							<p><span class="emphasis"><em>Matching_Distances</em></span>: it presents
								the distance computed of a record from its master record.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p><span class="emphasis"><strong>Built-in</strong></span>: You create and store
								the schema locally for this component only. Related topic: see
									<span class="emphasis"><em>Talend Data Integration Studio User
									Guide</em></span>.</p>
						</td></tr><tr><td>&nbsp;</td><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p><span class="emphasis"><strong>Repository</strong></span>: You have already
								created and stored the schema in the Repository. You can reuse it in
								other projects and job designs. Related topic: see <span class="emphasis"><em>Talend Data Integration Studio User Guide</em></span>.</p>
						</td></tr><tr><td>&nbsp;</td><td>
							<p>
								<span class="emphasis"><em>Link with a tMatchGroupHadoop</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box if more than one <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> is used in the Job. In the
									<span class="emphasis"><strong>Component</strong></span> field, select the
								relevant <span class="emphasis"><strong>tMatchGroupHadoop</strong></span>
								component to reuse the Hadoop connection details you already
								defined.</p>
						</td></tr><tr><td>&nbsp;</td><td>
							<p>
								<span class="emphasis"><em>Link with a tGenKeyHadoop</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box if you need to reuse a specific connection,
								created by a <span class="emphasis"><strong>tGenKeyHadoop</strong></span>, to the
								HDFS file. </p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td>
							<p>
								<span class="emphasis"><em>Hadoop version</em></span>
							</p>
						</td><td valign="top">
							<p>Select the Hadoop version of interest from the given list.</p>
						</td></tr><tr><td>&nbsp;</td><td>
							<p>
								<span class="emphasis"><em>Use an existing connection</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box and in the <span class="emphasis"><strong>Component List</strong></span> click the
		HDFS connection component from which you want to reuse the connection details already
		defined.</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When a Job contains the parent Job and the child Job, <span class="emphasis"><strong>Component
				list</strong></span> presents only the connection components in the same Job level.</p></div>
						</td></tr><tr><td>
							<p>
								<span class="emphasis"><em>Hadoop configuration</em></span>
							</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>Unavailable if you use an existing link.</p></div>
						</td><td>
							<span class="emphasis"><em>Host</em></span>
						</td><td valign="top">Type in the IP address of the Hadoop server to be
							connected to.</td></tr><tr><td>&nbsp;</td><td>
							<span class="emphasis"><em>Port</em></span>
						</td><td valign="top">Type in the listening port number of the Hadoop server
							to be connected to.</td></tr><tr><td>&nbsp;</td><td>
							<span class="emphasis"><em>HDFS directory</em></span>
						</td><td valign="top">
							<p>Enter the HDFS directory where the data to be processed is. </p>
							<p>At runtime, this component will clean up any data in this
								directory if it exists, write the input data in and perform the
								operations.</p>
							<p>If you want to reuse the existing data in HDFS, use:</p>
							<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>
										<span class="emphasis"><strong>Link with a tGenKeyHadoop</strong></span>
									</p></li><li class="listitem"><p>
										<span class="emphasis"><strong>Link with a
											tMatchGroupHadoop</strong></span>
									</p></li><li class="listitem"><p>
										<span class="emphasis"><strong>Use existing HDFS file</strong></span>
									</p></li></ul></div>
						</td></tr><tr><td>&nbsp;</td><td>
							<span class="emphasis"><em>User name</em></span>
						</td><td valign="top">User authentication name of HDFS.</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><em>Key Definition</em></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Input Key Attribute</em></span>
							</p>
						</td><td valign="top">
							<p>Select the column(s) from the input flow on which you want to
								apply a matching algorithm.</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When you select a date column on which to apply an algorithm or a matching algorithm,
			you can decide what to compare in the date format.</p><p>For example, if you want to only compare the year in the date, in the component schema
			set the type of the date column to <span class="emphasis"><strong>Date</strong></span> and then enter
				"<span class="emphasis"><em>yyyy</em></span>" in the <span class="emphasis"><strong>Date
				Pattern</strong></span> field. The component then converts the date format to a string
			according to the pattern defined in the schema before starting a string
			comparison.</p></div>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Matching Type</em></span>
							</p>
						</td><td valign="top">
							<p>Select the relevant matching algorithm from the list:</p>
							<p><span class="emphasis"><strong>Exact Match</strong></span>: matches each
								processed entry to all possible reference entries with exactly the
								same value. It returns <span class="emphasis"><em>1</em></span> when the two strings
								exactly match, and <span class="emphasis"><em>0</em></span> otherwise.</p>
							<p><span class="emphasis"><strong>Exact - ignore case</strong></span>: matches each
								processed entry to all possible reference entries with exactly the
								same value while ignoring the value case.</p>
							<p><span class="emphasis"><strong>Soundex</strong></span>: matches processed
								entries according to a standard English phonetic algorithm. It
								indexes strings by sound, as pronounced in English, for example
								"Hello": "H400".</p>
							<p><span class="emphasis"><strong>Levenshtein</strong></span> (edit distance):
								calculates the minimum number of edits (insertion, deletion or
								substitution) required to transform one string into another. Using
								this algorithm in the <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> component, you do not need to
								specify a maximum distance. The component automatically calculates a
								matching percentage based on the distance. This matching score will
								be used for the global matching calculation, based on the weight you
								assign in the<span class="emphasis"><strong> Confidence Weight</strong></span>
								field.</p>
							<p><span class="emphasis"><strong>Metaphone</strong></span>: Based on a phonetic
								algorithm for indexing entries by their pronunciation. It first
								loads the phonetics of all entries of the lookup reference and
								checks all entries of the main flow against the entries of the
								reference flow.</p>
							<p><span class="emphasis"><strong>Double Metaphone</strong></span>: a new version
								of the Metaphone phonetic algorithm, that produces more accurate
								results than the original algorithm. It can return both a primary
								and a secondary code for a string. This accounts for some ambiguous
								cases as well as for multiple variants of surnames with common
								ancestry.</p>
							<p><span class="emphasis"><strong>Soundex FR</strong></span>: matches processed
								entries according to a standard French phonetic algorithm.</p>
							<p><span class="emphasis"><strong>Jaro</strong></span>: matches processed entries
								according to spelling deviations. It counts the number of matched
								characters between two strings. The higher the distance is, the more
								similar the strings are.</p>
							<p><span class="emphasis"><strong>Jaro-Winkler</strong></span>: a variant of Jaro,
								but it gives more importance to the beginning of the string.</p>
							<p><span class="emphasis"><strong>q-grams</strong></span>: matches processed
								entries by dividing strings into letter blocks of length
									<code class="code">q</code> in order to create a number of <code class="code">q
								</code>length grams. The matching result is given as the number of
								q-gram matches over possible q-grams.</p>
							<p><span class="emphasis"><strong>custom...</strong></span>: enables you to load an
								external matching algorithm from a Java library. The <span class="emphasis"><strong>custom matcher class</strong></span> column alongside is
								activated when you selected this option.</p>
							<p> For further information about how to load an external Java
								library, see <a class="xref" href="tLibraryLoad.html" title="tLibraryLoad">the section called &#8220;tLibraryLoad&#8221;</a>.</p>
							<p> For further information about how to create a custom matching
								algorithm, see <a class="xref" href="tRecordMatching.html#Raa71983" title="Creating a custom matching algorithm">the section called &#8220;Creating a custom matching algorithm&#8221;</a>.</p>
							<p> For the related scenario about how to use a custom matching
								algorithm, see <a class="xref" href="tRecordMatching.html#Raa86106" title="Scenario 2: Using a custom matching algorithm to match entries">the section called &#8220;Scenario 2: Using a custom matching algorithm to match entries&#8221;</a>.</p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<span class="emphasis"><em>Custom matcher class</em></span>
						</td><td valign="top">
							<p>Type in the path pointing to the custom class (external matching
								algorithm) you need to use. This path is defined by yourself in the
								library file (<span class="emphasis"><em>.jar</em></span> file).</p>
							<p>For example, to use a <span class="emphasis"><em>MyDistance.class</em></span> class
								stored in the directory <span class="emphasis"><em>org/talend/mydistance</em></span>
								in a user-defined <span class="emphasis"><em>mydistance.jar</em></span> library, the
								path to be entered is
									<span class="emphasis"><em>org.talend.mydistance.MyDistance</em></span>.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Confidence Weight</em></span>
							</p>
						</td><td valign="top">
							<p>Set a numerical weight for each attribute (column) of the key
								definition. The values can be anything &gt;= 0.</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>If you have more than one <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> components in your Job, the
									distances and the matching scores may not be coherent when the
									criteria you set to compute the distance is different in each
									component</p></div>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><em>Blocking Definition</em></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Input Column</em></span>
							</p>
						</td><td valign="top">
							<p>If required, select the column(s), as the blocking key(s), from
								the input flow depending on which you want to partition the
								processed data in blocks, this is usually referred to as &#8220;blocking&#8221;. </p>
							<p>Blocking reduces the number of pairs of records that needs to be
								examined. In blocking, input data is partitioned into exhaustive
								blocks designed to increase the proportion of matches observed while
								decreasing the number of pairs to compare. Comparisons are
								restricted to record pairs within each block.</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>Using blocking column(s) is very useful when you are
									processing very big data.</p></div>
						</td></tr><tr><td>
							<p>&nbsp; <span class="emphasis"><strong>Advanced settings</strong></span>
							</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Matching Algorithm</em></span>
							</p>
						</td><td valign="top">
							<p>Select an algorithm from the list - only one is available for the
								time being. </p>
							<p><span class="emphasis"><strong>Simple VSR Matcher</strong></span>: This
								algorithm is based on a Vector Space Retrieval method that specifies
								how two records may match.</p>
							<p><span class="emphasis"><strong>Match Interval</strong></span>: Enter the match
								probability. Two data records match when the probability is above
								the set value.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Sort the output data by GID</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to group the output data by the group
								ID.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Output distance details</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to fill the fixed output column
									<span class="emphasis"><em>MATCHING_DISTANCES</em></span> with the details of the
								distance between each column. This check box becomes unavailable
								when you select the <span class="emphasis"><strong>Link with a
									tMatchGroupHadoop</strong></span> check box.</p>
						</td></tr><tr><td>
							<p>
								<span class="emphasis"><em>Hadoop Properties</em></span>
							</p>
							<div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>Unavailable if you use an existing link.</p></div>
						</td><td valign="top">
							<span class="emphasis"><em>Property</em></span>
						</td><td valign="top">
							<p>If you need to use custom configuration for the Hadoop of
		interest, complete this table with the property or properties to be
		customized. Then at runtime, the customized property or properties
		will override those corresponding ones defined earlier for the same
		Hadoop. </p>
							<p>For further information about the properties required by Hadoop,
		see the Hadoop documentation. </p>
						</td></tr><tr><td>&nbsp;</td><td valign="top">
							<span class="emphasis"><em>Value</em></span>
						</td><td valign="top">
							<p>Type in the custom property values used to connect to the Hadoop
								of interest.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Keep data in Hadoop</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to keep the data processed by this component
								in the HDFS file.</p>
							<p>If you leave this check box unselected, the component processes
								data and then retrieves it from the HDFS file and output it in the
								Job flow.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>Use existing HDFS file</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to enable the component to directly process
								the data in an HDFS file. When this check box is selected, this
								component can act as a start component in your Job.</p>
							<p><span class="emphasis"><strong>HDFS file URI</strong></span>: set the URI of the
								HDFS file holding the data you want to process.</p>
							<p><span class="emphasis"><strong>Field delimiter</strong></span>: set the
								character used as a field delimiter in the HDFS file.</p>
							<p>If you leave this check box unselected, <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> receives the data flow to be
								processed and loads it into an HDFS file.</p>
						</td></tr><tr><td>
							<p>&nbsp;</p>
						</td><td valign="top">
							<p>
								<span class="emphasis"><em>tStatCatcher Statistics</em></span>
							</p>
						</td><td valign="top">
							<p>Select this check box to collect log data at the component
								level.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Dynamic settings</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>Click the <span class="emphasis"><strong>[+]</strong></span> button to add a row
								in the table and fill the <span class="emphasis"><strong>Code</strong></span>
								field with a context variable to choose your HDFS connection
								dynamically from multiple connections planned in your Job. </p>
							<p>The <span class="emphasis"><strong>Dynamic settings</strong></span> table is available only when the
			<span class="emphasis"><strong>Use an existing connection</strong></span> check box is selected in the
			<span class="emphasis"><strong>Basic settings</strong></span> view. When a dynamic parameter is
		defined, the <span class="emphasis"><strong>Component List</strong></span> box in the <span class="emphasis"><strong>Basic settings</strong></span> view becomes unusable. </p>
							<p>For more information on <span class="emphasis"><strong>Dynamic settings</strong></span> and context
		variables, see <span class="emphasis"><em>Talend Data Integration Studio User Guide</em></span>.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Usage</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>This component can be a start or an intermediary step. It requires
								an input flow as an intermediary step and an output flow as either
								of the step types. It needs the connection to Hadoop for processing
								large volume of data.</p>
							<p>It is ideally used alongside the <span class="emphasis"><strong>tGenKey</strong></span> component or the<span class="emphasis"><strong>
									tGenKeyHadoop</strong></span> component in order to use the blocking
								columns, provided by either of the components, to gain a better
								performance. In practice, we recommend placing the most restrictive
								blocking criteria in the first <span class="emphasis"><strong>tGenKey</strong></span> or the first <span class="emphasis"><strong>tGenKeyHadoop</strong></span> component in use.</p>
						</td></tr><tr><td valign="top">
							<p>
								<span class="emphasis"><strong>Limitation/prerequisite</strong></span>
							</p>
						</td><td colspan="2" valign="top">
							<p>You need to use Linux to execute the Job containing this
								component. </p>
						</td></tr></tbody></table></div><div class="section" title="Working principle"><div class="titlepage"><div><div><h4 class="title"><a name="d0e97774"></a>Working principle</h4></div></div></div><p>This component implements the MapReduce model, based on the blocking keys defined
				in the <span class="emphasis"><strong>Blocking definition</strong></span> table of the <span class="emphasis"><strong>Basic settings</strong></span> view.</p><div class="mediaobject" align="center"><img src="../images/mapreduce.png" align="middle"></div><p>This implementation proceeds as follows:</p><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Splits the input rows in groups of a given size.</p></li><li class="step" title="Step 2"><p>Implements a Map Class that creates a map between each key and a list of
						records.</p></li><li class="step" title="Step 3"><p>Shuffles the records to group those with the same key together.</p></li><li class="step" title="Step 4"><p>Applies, on each key, the algorithm defined in the <span class="emphasis"><strong>Key definition</strong></span> table of the <span class="emphasis"><strong>Basic
							settings</strong></span> view.</p><p>Then accordingly, this component reads the records, compares them with the
						master records, groups the similar ones, and classes each of the rest as a
						master record.</p></li><li class="step" title="Step 5"><p>Outputs the groups of similar records with their group IDs, group sizes,
						matching distances and scores.</p></li></ol></div></div></div><div class="section" title="Scenario: Running customer matching through multiple passes"><div class="titlepage"><div><div><h3 class="title"><a name="ychen-20111205-tmatchgrouphadoop-multiple_passes"></a>Scenario: Running customer matching through multiple passes </h3></div></div></div><p>The Job in this scenario connects to the given Hadoop system, groups similar customer
			records by running through two subsequent matching passes in HDFS and outputs the
			calculated matches by groups. Each pass provides its matches to the pass that follows in
			order for the latter to add more matches identified with new rules.</p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-scenario.png" align="middle"></div><p>The components of interest are:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p><span class="emphasis"><strong>tFixedFlowInput</strong></span>: it provides the customer
					records to be processed.</p></li><li class="listitem"><p>two <span class="emphasis"><strong>tGenKeyHadoop</strong></span> components: Each defines a
					way to partition the records...</p></li><li class="listitem"><p>two <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> components: they
					process each partition to group the records within and once configured, sort the
					groups by their group IDs. The first <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> processes the partitions defined by the first
						<span class="emphasis"><strong>tGenKeyHadoop</strong></span> and the second <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> processes those defined by the
					second <span class="emphasis"><strong>tGenKeyHadoop</strong></span>. Each of them set one pass
					to match the received records.</p><div class="warning" title="Warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>The two <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> components
							must have the same schema.</p></div></li><li class="listitem"><p>two <span class="emphasis"><strong>tLogRow</strong></span> components: they present the
					execution result of each <span class="emphasis"><strong>tMatchGroupHadoop</strong></span>
					component.</p></li></ul></div><p>To replicate this scenario, proceed as the following sections illustrate.</p><div class="section" title="Dropping and linking the components"><div class="titlepage"><div><div><h4 class="title"><a name="d0e97871"></a>Dropping and linking the components</h4></div></div></div><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Drop <span class="emphasis"><strong>tFixedFlowInput</strong></span>, two <span class="emphasis"><strong>tGenKeyHadoop</strong></span> components, two <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> components and two <span class="emphasis"><strong>tLogRow</strong></span> components from <span class="emphasis"><strong>Palette</strong></span> onto the design workspace.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>A component used in the workspace can be labelled the way you need. In
							this scenario, this input component is labelled
								<span class="emphasis"><em>incoming_customers</em></span> for <span class="emphasis"><strong>tFixedFlowInput</strong></span>. For further information about how to
							label a component, see <span class="emphasis"><em>Talend Data Integration Studio</em></span>
							<span class="emphasis"><em>User Guide</em></span></p></div></li><li class="step" title="Step 2"><p>Right-click <span class="emphasis"><strong>tFixedFlowInput</strong></span> to open its
						contextual menu and select the <span class="emphasis"><strong>Row</strong></span> &gt;
							<span class="emphasis"><strong>Main</strong></span> link from this menu to connect
						this component to the first <span class="emphasis"><strong>tGenKeyHadoop</strong></span>
						(labeled <span class="emphasis"><em>lname_postcode</em></span>).</p></li><li class="step" title="Step 3"><p>Do the same to create the <span class="emphasis"><strong>Main</strong></span> link from
						the first <span class="emphasis"><strong>tGenKeyHadoop</strong></span> to the second
							<span class="emphasis"><strong>tGenKeyHadoop</strong></span> (labeled <span class="emphasis"><em>lname_initial</em></span>), to the first <span class="emphasis"><strong>tMatchGroupHadoop</strong></span>, to the first <span class="emphasis"><strong>tLogRow</strong></span> and then to the second <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> and finally to the second
							<span class="emphasis"><strong>tLogRow</strong></span>.</p></li></ol></div><p>The components to be used in this scenario are all placed and linked. Then you
				need continue to configure them successively. </p></div><div class="section" title="Configuring the input flow"><div class="titlepage"><div><div><h4 class="title"><a name="d0e97954"></a>Configuring the input flow</h4></div></div></div><div class="procedure" title="Procedure&nbsp;6.1.&nbsp;Setting up the input data"><a name="d0e97957"></a><p class="title"><b>Procedure&nbsp;6.1.&nbsp;Setting up the input data</b></p><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click <span class="emphasis"><strong>tFixedFlowInput</strong></span> to open its
							<span class="emphasis"><strong>Component</strong></span> view.</p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-inputflow.png" align="middle"></div></li><li class="step" title="Step 2"><p> Click the three-dot button next to <span class="emphasis"><strong>Edit
							schema</strong></span> to open the schema editor.</p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-input_schema.png" align="middle"></div></li><li class="step" title="Step 3"><p>Click the plus button eight times to add eight rows. They are the eight
						columns of the schema of the input data.</p></li><li class="step" title="Step 4"><p>Rename these eight rows respectively. In this example, they are: <span class="emphasis"><em>account_num</em></span>, <span class="emphasis"><em>lname</em></span>, <span class="emphasis"><em>fname</em></span>, <span class="emphasis"><em>mi</em></span>, <span class="emphasis"><em>address1</em></span>, <span class="emphasis"><em>city</em></span>, <span class="emphasis"><em>state_province</em></span>, <span class="emphasis"><em>postal_code</em></span>.</p></li><li class="step" title="Step 5"><p>In the <span class="emphasis"><strong>Type</strong></span> column, select the data types
						for the rows of interest. In this example, select <span class="emphasis"><strong>Long</strong></span> for the <span class="emphasis"><em>account_num</em></span>
						column.</p></li><li class="step" title="Step 6"><p>Click <span class="emphasis"><strong>OK</strong></span> to validate these changes and
						accept the propagation prompted by the pop-up dialog box.</p></li><li class="step" title="Step 7"><p>In the <span class="emphasis"><strong>Mode</strong></span> area of the <span class="emphasis"><strong>Basic settings</strong></span> view, select <span class="emphasis"><strong>Use Inline Content (delimited file)</strong></span> to enter the input data
						of interest.</p></li><li class="step" title="Step 8"><p>In the <span class="emphasis"><strong>Content</strong></span> field, enter the input
						data to be processed, or paste the sample data provided by the demo Job
							<span class="emphasis"><em>D4_hadoop_group_family_multipass</em></span> that
						you could import along with the demo DQ project. For further information
						about how to import a project, see <span class="emphasis"><em>Talend Data Integration Studio</em></span>
						<span class="emphasis"><em>User Guide</em></span>.</p></li></ol></div><div class="procedure" title="Procedure&nbsp;6.2.&nbsp;Configuring the key generation for the first pass"><a name="d0e98056"></a><p class="title"><b>Procedure&nbsp;6.2.&nbsp;Configuring the key generation for the first pass</b></p><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click the first <span class="emphasis"><strong>tGenKeyHadoop</strong></span>
						(labelled <span class="emphasis"><em>lname_postcode</em></span>) to open the
							<span class="emphasis"><strong>Component</strong></span> view. </p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-genkey1.png" align="middle"></div></li><li class="step" title="Step 2"><p>Configure the connection to the HDFS you want to write and process the
						records in. </p><p>The parameters to be set are the <span class="emphasis"><strong>Hadoop
							version</strong></span>, the <span class="emphasis"><strong>Host</strong></span>, the
							<span class="emphasis"><strong>Port</strong></span>, the <span class="emphasis"><strong>HDFS
							directory</strong></span> and the <span class="emphasis"><strong>User
						name</strong></span>.</p><p>In the HDFS directory you define, this component will create, at runtime,
						the folder storing separately the input records and the same records but
						with their partition keys: the original ones in an <span class="emphasis"><em>in</em></span> folder and the partitioned ones in an <span class="emphasis"><em>out</em></span> folder, both under the same parental folder
							<span class="emphasis"><em>tGenKeyHadoop_1</em></span></p></li><li class="step" title="Step 3"><p>Under the <span class="emphasis"><strong>Algorithm</strong></span> table, click the plus
						button to add two rows in this table.</p></li><li class="step" title="Step 4"><p>On the <span class="emphasis"><strong>column</strong></span> column, click the newly
						added row and select, from the list, the column you want to process using an
						algorithm. In this example, select <span class="emphasis"><em>lname</em></span>.</p></li><li class="step" title="Step 5"><p>Do the same on the second row to select
						<span class="emphasis"><em>postal_code</em></span></p></li><li class="step" title="Step 6"><p>On the <span class="emphasis"><strong>pre-algorithm</strong></span> column, click the
						newly added row and select, from the list, the pre-algorithm you want to
						apply to the corresponding column. In this example, select <span class="emphasis"><strong>remove diacritical marks and upper case</strong></span> to remove
						any diacritical mark and converts the fields of the <span class="emphasis"><em>lname</em></span> column to upper case before generating the code of
						this column.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>This conversion does not change your raw data.</p></div></li><li class="step" title="Step 7"><p>On the <span class="emphasis"><strong>algorithm</strong></span> column, click the newly
						added row and select from the list the algorithm you want to apply to the
						corresponding column. In this example, select <span class="emphasis"><strong>N first
							characters of each word</strong></span>.</p></li><li class="step" title="Step 8"><p>Do the same for the second row on the <span class="emphasis"><strong>algorithm</strong></span> column to select <span class="emphasis"><strong>first N
							characters of the string</strong></span>.</p></li><li class="step" title="Step 9"><p>Click in the <span class="emphasis"><strong>Value</strong></span> column next to the
							<span class="emphasis"><strong>algorithm</strong></span> column and enter the value
						for the selected algorithm, when needed. In this scenario, type in
							<span class="emphasis"><em>1</em></span> for both of the rows, meaning that the first
						letter of each field in the corresponding columns will be used to generate
						the keys.</p></li><li class="step" title="Step 10"><p>Click <span class="emphasis"><strong>Advanced settings</strong></span> to open its view. </p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-genkey1-advanced_settings.png" align="middle"></div></li><li class="step" title="Step 11"><p>Select the <span class="emphasis"><strong>Keep data in Hadoop</strong></span> check box
						in order to process data in HDFS. In this situation, the customer records
						are not outputted into the data flow and the process runs faster.</p></li></ol></div><div class="procedure" title="Procedure&nbsp;6.3.&nbsp;Configuring the key generation for the second pass"><a name="d0e98184"></a><p class="title"><b>Procedure&nbsp;6.3.&nbsp;Configuring the key generation for the second pass</b></p><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click the second <span class="emphasis"><strong>tGenKeyHadoop</strong></span>
						(labelled <span class="emphasis"><em>lname_initial</em></span>) to open the
							<span class="emphasis"><strong>Component</strong></span> view. </p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-genkey2.png" align="middle"></div></li><li class="step" title="Step 2"><p>Select <span class="emphasis"><strong>Link with a tGenKeyHadoop</strong></span> to reuse
						the connection to HDFS and the HDFS directory created by the first <span class="emphasis"><strong>tGenKeyHadoop.</strong></span>. This reuse enables this component
						to read the data processed by its preceding <span class="emphasis"><strong>tGenKeyHadoop</strong></span> component natively in HDFS.</p></li><li class="step" title="Step 3"><p>Click the <span class="inlinemediaobject"><img src="../images/DotButton.png" align="middle"></span> button to verify the key column in the schema. You can
						find that the key columns of the two <span class="emphasis"><strong>tGenKeyHadoop</strong></span> components have been automatically named to
						differentiate each other. In this scenario, they are <span class="emphasis"><em>T_GEN_KEY_postcode</em></span> and <span class="emphasis"><em>T_GEN_KEY</em></span>.</p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-genkeyschema.png" align="middle"></div></li><li class="step" title="Step 4"><p>Under the <span class="emphasis"><strong>Algorithm</strong></span> table, click the plus
						button to add one row in this table.</p></li><li class="step" title="Step 5"><p>On the <span class="emphasis"><strong>column</strong></span> column, click the newly
						added row and select from the list the column you want to process using an
						algorithm. In this example, select <span class="emphasis"><em>account_num</em></span>.</p></li><li class="step" title="Step 6"><p>On the <span class="emphasis"><strong>algorithm</strong></span> column, click the newly
						added row and select from the list the algorithm you want to apply to the
						corresponding column. In this example, select <span class="emphasis"><strong>first N
							characters of the string</strong></span>.</p></li><li class="step" title="Step 7"><p>Click in the <span class="emphasis"><strong>Value</strong></span> column next to the
							<span class="emphasis"><strong>algorithm</strong></span> column and enter the value
						for the selected algorithm, when needed. In this scenario, type in
							<span class="emphasis"><em>1</em></span>, meaning that the first letter of each field in
						the corresponding column will be used to generate the required keys.</p></li><li class="step" title="Step 8"><p>Click <span class="emphasis"><strong>Advanced settings</strong></span> to open its
						view.</p></li><li class="step" title="Step 9"><p>Select the <span class="emphasis"><strong>Keep data in Hadoop</strong></span> check box
						in order to process data in HDFS.</p></li></ol></div></div><div class="section" title="Configuring the two passes"><div class="titlepage"><div><div><h4 class="title"><a name="d0e98281"></a>Configuring the two passes</h4></div></div></div><p>You need to configure the two passes to group the input data with the help of the
				two columns of generated keys.</p><div class="procedure" title="Procedure&nbsp;6.4.&nbsp;Configuring the first pass"><a name="d0e98286"></a><p class="title"><b>Procedure&nbsp;6.4.&nbsp;Configuring the first pass</b></p><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click the first <span class="emphasis"><strong>tMatchGroupHadoop</strong></span>
						component (labelled <span class="emphasis"><em>pass1</em></span>) to display the
							<span class="emphasis"><strong>Component</strong></span> view.</p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-pass1.png" align="middle"></div></li><li class="step" title="Step 2"><p>If required, click <span class="emphasis"><strong>Sync schema</strong></span>, then
						click <span class="emphasis"><strong>Edit schema</strong></span> to open the schema editor
						and see the schema retrieved from the previous component in the Job.</p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-pass1_schema.png" align="middle"></div></li><li class="step" title="Step 3"><p>Select <span class="emphasis"><strong>Link with a tGenKeyHadoop</strong></span> to reuse
						the connection to HDFS and the HDFS diretory created by its preceding
							<span class="emphasis"><strong>tGenKeyHadoop.</strong></span>. This reuse enables this
						component to read the data processed by that tGenKeyHadoop component
						natively in HDFS.</p></li><li class="step" title="Step 4"><p>In the <span class="emphasis"><strong>Key definition</strong></span> table, click <span class="inlinemediaobject"><img src="../images/plus_button.png" align="middle"></span> to add to the list the columns on which you want to do
						the matching operation, <span class="emphasis"><em>lname</em></span> in this
						scenario.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When you select a date column on which to apply an algorithm or a matching algorithm,
			you can decide what to compare in the date format.</p><p>For example, if you want to only compare the year in the date, in the component schema
			set the type of the date column to <span class="emphasis"><strong>Date</strong></span> and then enter
				"<span class="emphasis"><em>yyyy</em></span>" in the <span class="emphasis"><strong>Date
				Pattern</strong></span> field. The component then converts the date format to a string
			according to the pattern defined in the schema before starting a string
			comparison.</p></div></li><li class="step" title="Step 5"><p>Click in the first and second cells of the <span class="emphasis"><strong>Matching
							type</strong></span> column and select from the list the method(s) to be used
						for the matching operation, <span class="emphasis"><em>Jaro-Winkler</em></span> in this
						example.</p></li><li class="step" title="Step 6"><p>Click the plus button below the <span class="emphasis"><strong>Blocking
							Definition</strong></span> table to add one row in the table then click in
						the line and select from the list the column you want to use as a blocking
						value, <span class="emphasis"><em>T_GEN_KEY_postcode</em></span> in this
						example. </p><p>Using a blocking value reduces the number of pairs of records that needs
						to be examined. The input data is partitioned into exhaustive blocks based
						on the functional key. This will decrease the number of pairs to compare, as
						comparison is restricted to record pairs within each block. </p></li><li class="step" title="Step 7"><p>Click <span class="emphasis"><strong>Advanced settings</strong></span> to open its view
						to verify that the<span class="emphasis"><strong> Keep data in Hadoop</strong></span> is
						clear. This way, the processed customer records are outputted into the data
						flow and therefore, become available to <span class="emphasis"><strong>tLogRow</strong></span>. </p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-pass1-advanced_settings.png" align="middle"></div></li><li class="step" title="Step 8"><p>Select the <span class="emphasis"><strong>Sort the output data by GID</strong></span>
						check box to arrange the output data by their group IDs. </p></li></ol></div><div class="procedure" title="Procedure&nbsp;6.5.&nbsp;Configuring the second pass"><a name="d0e98393"></a><p class="title"><b>Procedure&nbsp;6.5.&nbsp;Configuring the second pass</b></p><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click the second <span class="emphasis"><strong>tMatchGroupHadoop</strong></span>
						component (labelled <span class="emphasis"><em>pass2</em></span>) to display the
							<span class="emphasis"><strong>Component</strong></span> view.</p><div class="mediaobject" align="center"><img src="../images/tmatchgroupHadoop-pass2.png" align="middle"></div></li><li class="step" title="Step 2"><p>If this component does not have the same schema of the preceding
						component, a warning icon appears. In this situation, click the <span class="emphasis"><strong>Sync columns</strong></span> button to retrieve the schema from
						the preceding one and once done, the warning icon disappears.</p></li><li class="step" title="Step 3"><p>Select the <span class="emphasis"><strong>Link with a tMatchGroupHadoop</strong></span>
						check box to reuse the connection of its preceding <span class="emphasis"><strong>tMatchGroupHadoop</strong></span> to the Hadoop system.</p></li><li class="step" title="Step 4"><p>In the <span class="emphasis"><strong>Key definition</strong></span> table, click the
						plus button to add to the list the columns on which you want to do the
						matching operation, <span class="emphasis"><em>lname</em></span> in this
						scenario.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>When you select a date column on which to apply an algorithm or a matching algorithm,
			you can decide what to compare in the date format.</p><p>For example, if you want to only compare the year in the date, in the component schema
			set the type of the date column to <span class="emphasis"><strong>Date</strong></span> and then enter
				"<span class="emphasis"><em>yyyy</em></span>" in the <span class="emphasis"><strong>Date
				Pattern</strong></span> field. The component then converts the date format to a string
			according to the pattern defined in the schema before starting a string
			comparison.</p></div></li><li class="step" title="Step 5"><p>Click in the cell of the <span class="emphasis"><strong>Matching type</strong></span>
						column and select from the list the method(s) to be used for the matching
						operation, <span class="emphasis"><em>Jaro-Winkler</em></span> in this
						example.</p></li><li class="step" title="Step 6"><p>Click <span class="inlinemediaobject"><img src="../images/plus_button.png" align="middle"></span> below the <span class="emphasis"><strong>Blocking
							Definition</strong></span> table to add one row in the table then click in
						the row and select from the list the column you want to use as a blocking
						value, <span class="emphasis"><em>T_GEN_KEY</em></span> in this example. This
						way, the matching operation is performed only between the master records
						with the same key, in this example, the same initial character of the
						account numbers. </p><p>Through this pass, this Job processes the matching groups provided by the
						previous <span class="emphasis"><strong>tMatchGroupHadoop</strong></span>. It selects the
						groups with one single record to compare with the other master records when
						both parts of them have the same generated key.</p></li><li class="step" title="Step 7"><p>Click <span class="emphasis"><strong>Advanced settings</strong></span> to open its view
						to verify that the<span class="emphasis"><strong> Keep data in Hadoop</strong></span> is
						clear. This way, the processed customer records are outputted into the data
						flow and therefore, become available to<span class="emphasis"><strong>
							tLogRow</strong></span>.</p></li><li class="step" title="Step 8"><p>Select the <span class="emphasis"><strong>Sort the output data by GID</strong></span>
						check box to arrange the output data by their group IDs. </p></li></ol></div><div class="procedure" title="Procedure&nbsp;6.6.&nbsp;Sorting the input records"><a name="d0e98494"></a><p class="title"><b>Procedure&nbsp;6.6.&nbsp;Sorting the input records</b></p><ol class="procedure" type="1"><li class="step" title="Step 1"><p>Double-click <span class="emphasis"><strong>tSortRow</strong></span> to open its
							<span class="emphasis"><strong>Component</strong></span> view.</p><div class="mediaobject" align="center"><img src="../images/tmatchgrouphadoop-sortrow.png" align="middle"></div></li><li class="step" title="Step 2"><p>Under the <span class="emphasis"><strong>Criteria</strong></span> table, click the plus
						button twice to add two rows.</p></li><li class="step" title="Step 3"><p>In the first row, select <span class="emphasis"><em>GID</em></span> for the
							<span class="emphasis"><strong>Schema column</strong></span> column, <span class="emphasis"><em>alpha</em></span> for the <span class="emphasis"><strong>Sort num or
							alpha</strong></span> column and <span class="emphasis"><em>asc</em></span> for
						the <span class="emphasis"><strong>Order asc or desc</strong></span> column. This means
						that the sorting is performed on the <span class="emphasis"><em>GID</em></span>
						column of the input schema, in terms of its ascending alphabetical order.
						Thus the other columns are sorted accordingly.</p></li><li class="step" title="Step 4"><p>Do the same to select <span class="emphasis"><em>GRP_SIZE</em></span>,
							<span class="emphasis"><em>num</em></span> and <span class="emphasis"><em>desc</em></span> accordingly in the second row.</p></li></ol></div><p>Then you can run this Job.</p><p>The <span class="emphasis"><strong>tLogRow</strong></span> component is used to present the
				execution result of the Job.</p><div class="procedure"><ol class="procedure" type="1"><li class="step" title="Step 1"><p>If you want to configure the presentation mode on its <span class="emphasis"><strong>Component</strong></span> view, double-click the <span class="emphasis"><strong>tLogRow</strong></span> component of interest to open the
							<span class="emphasis"><strong>Component</strong></span> view and in the <span class="emphasis"><strong>Mode</strong></span> area, then, select the <span class="emphasis"><strong>Table (print values in cells of a table)</strong></span> check box.</p></li><li class="step" title="Step 2"><p>Press <span class="emphasis"><strong>F6</strong></span> to run this Job. </p></li></ol></div><p>Once done, the <span class="emphasis"><strong>Run</strong></span> view is opened automatically,
				where you can check the execution result.</p><p>The result after the first pass reads as follows:</p><div class="mediaobject" align="center"><img src="../images/tmatchgrouphadoop_multipass1.png" align="middle"></div><p>The result after the second pass reads as follows:</p><div class="mediaobject" align="center"><img src="../images/tmatchgrouphadoop_multipass2.png" align="middle"></div><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>For the reason of page space, the results are not totally presented.</p></div><p>When you compare, for example, the customer name <span class="emphasis"><em>Alexander</em></span> from the results of the two passes, you will find that
				more customers using the last name <span class="emphasis"><em>Alexander</em></span> are
				grouped together after the second pass:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p>In the first pass, <span class="emphasis"><em>Jeremy Alexander</em></span>,
							<span class="emphasis"><em>Bob Alexander</em></span> and <span class="emphasis"><em>Maxine Alexander</em></span> are not distributed in the
						same group because the matching is performed only within each block defined
						in the <span class="emphasis"><em>T_GEN_KEY_postcode</em></span> column while
						they belong to different blocks, A9, A8 and A3 respectively.</p></li><li class="listitem"><p>In the second pass, the matching to be performed uses the blocks defined
						in the <span class="emphasis"><em>T_GEN_KEY</em></span> column. As all of the
						three customer names belong to block <span class="emphasis"><em>2</em></span>,
						so they are grouped together after computing the distance in between. In
						addition, you can as well read, from the <span class="emphasis"><em>MASTER</em></span> column, that <span class="emphasis"><em>Jeremy
							Alexander</em></span> is the master record of its group. </p></li></ul></div></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="tMatchGroup.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="ch-dataquality.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="tMelissaDataAddress.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">tMatchGroup&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="bk-tdi-components-rg-en..html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;tMelissaDataAddress</td></tr></table></div></body></html>